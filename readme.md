Проект: Веб-сервис анализа тональности отзывов москвичей

1. Описание проекта

Цель проекта — разработать полноценный веб-сервис, который:
	•	принимает тексты отзывов москвичей (одиночные и в формате CSV);
	•	автоматически определяет их тональность (негативная, нейтральная, позитивная);
	•	позволяет скачивать размеченный CSV;
	•	показывает базовую аналитику по тональностям и источникам;
	•	умеет считать метрику качества модели (macro-F1) на валидационной выборке;
	•	развёрнут на бесплатном хостинге и доступен через веб-интерфейс.

Проект включает:
	•	Backend (API + модель машинного обучения).
	•	Frontend (веб-интерфейс для работы с сервисом).
	•	Код обучения модели и работы с данными.
	•	Инструкцию по запуску и деплою (этот README).

⸻

2. Функциональные требования

2.1. Классы тональности

Сервис работает с тремя классами тональности:
	•	0 — отрицательный отзыв;
	•	1 — нейтральный отзыв;
	•	2 — положительный отзыв.

Все модели и API ориентируются именно на эти три класса.

2.2. Формат данных

Базовый формат данных — CSV-файл со следующими колонками:
	•	text — текст отзыва (обязательное поле);
	•	label — корректная метка тональности 0/1/2 (необязательно для предсказаний, обязательно для валидации);
	•	src — источник отзыва (название сервиса, площадки или канала, например: app_store, mos_ru, vk, и т.п.).

Сервис должен уметь работать с:
	•	CSV без label — для предсказаний на новых данных;
	•	CSV с label — для оценки качества модели по метрике macro-F1.

2.3. Основные сценарии работы
	1.	Анализ одного текста
Пользователь вводит текст отзыва в форму на сайте → сервис возвращает предсказанную тональность (0/1/2 + словесное описание).
	2.	Пакетная классификация CSV
Пользователь загружает CSV с колонкой text (и опционально src) → сервис:
	•	прогоняет все строки через модель;
	•	добавляет столбец predicted_label;
	•	возвращает файл для скачивания;
	•	отображает краткую статистику по количеству отзывов каждого класса.
	3.	Оценка модели по macro-F1
Пользователь загружает CSV с колонками text и label → сервис:
	•	считает предсказания;
	•	сравнивает их с label;
	•	считает метрику macro-F1 и, по возможности, F1 для каждого класса;
	•	отображает результат на отдельной вкладке/странице.
	4.	Базовая аналитика на сайте
	•	Распределение тональностей по данным (круговая диаграмма или bar-chart).
	•	Топ источников по количеству отзывов.
	•	Возможность отфильтровать таблицу по тональности и источнику.

⸻

3. Технологический стек

Рекомендуемый стек (можно адаптировать под себя):

Backend
	•	Язык: Python 3.10+
	•	Фреймворк: FastAPI (можно заменить на Flask при желании)
	•	ML-библиотеки:
	•	scikit-learn (TF-IDF, линейные модели, метрики),
	•	опционально: pandas, numpy,
	•	при желании: pymorphy3 или другие инструменты для русской морфологии.
	•	Серилизация модели: joblib или pickle.
	•	Веб-сервер: uvicorn для локального запуска.

Frontend
	•	Минимальный вариант: чистый HTML + CSS + JS.
	•	Можно использовать:
	•	CSS-фреймворк: Bootstrap (по желанию);
	•	графики: Chart.js для визуализаций (pie/bar charts).

Прочее
	•	Управление зависимостями: pip + requirements.txt.
	•	Контейнеризация (по желанию): Docker.
	•	Система контроля версий: git.
	•	Хостинг:
	•	сайт — любой бесплатный PaaS (Render, Railway, etc. — зависит от требований),
	•	репозиторий — Mos.Hub / GitHub.

⸻

4. Структура репозитория

Пример предлагаемой структуры:

project-root/
├─ backend/
│  ├─ app/
│  │  ├─ main.py            # Точка входа FastAPI
│  │  ├─ models.py          # Pydantic-схемы запросов/ответов
│  │  ├─ ml_model.py        # Загрузка и использование ML-модели
│  │  ├─ preprocessing.py   # Текстовая предобработка
│  │  ├─ utils.py           # Вспомогательные функции
│  │  └─ config.py          # Настройки, пути, константы
│  ├─ model_artifacts/
│  │  ├─ model.joblib       # Обученная модель
│  │  └─ vectorizer.joblib  # TF-IDF / др. векторизатор (если отдельно)
│  └─ requirements.txt      # Зависимости бэкенда
│
├─ ml/
│  ├─ train_model.py        # Скрипт обучения модели
│  ├─ evaluate_model.py     # Скрипт оценки модели (опционально)
│  ├─ data/
│  │  ├─ train.csv          # Обучающая выборка
│  │  ├─ val.csv            # Валидационная выборка
│  │  └─ test.csv           # Тестовая выборка (опционально)
│  └─ notebooks/            # Jupyter-ноутбуки для экспериментов (по желанию)
│
├─ database/
│  └─ schema.sql            # DDL для PostgreSQL (история батчей, метрики, источники)
│
├─ frontend/
│  ├─ index.html            # Главная страница
│  ├─ css/
│  │  └─ styles.css         # Стили
│  ├─ js/
│  │  ├─ app.js             # Общая логика фронта
│  │  ├─ api.js             # Вызовы API бэкенда через fetch
│  │  └─ charts.js          # Код отрисовки графиков (Chart.js)
│  └─ assets/               # Картинки, иконки (если нужны)
│
├─ docker/
│  ├─ Dockerfile.backend    # Dockerfile для бэка (опционально)
│  └─ docker-compose.yml    # Композиция (если понадобится)
│
├─ README.md                # Текущий файл с описанием
└─ .gitignore

Эта структура не обязательна, но помогает держать код в порядке.

⸻

5. Backend: API и логика

5.1. Предобработка текста

Базовый pipeline предобработки:
	1.	Приведение к нижнему регистру.
	2.	Удаление лишних пробелов, символов пунктуации (по необходимости).
	3.	(Опционально) Удаление стоп-слов.
	4.	(Опционально) Лемматизация/стемминг для русского языка.

Эта логика живёт в preprocessing.py и используется как при обучении, так и при предсказаниях.

5.2. Обученная модель

Модель хранится в backend/model_artifacts/:
	•	model.joblib — сама модель (например, LinearSVC или LogisticRegression).
	•	vectorizer.joblib — TF-IDF или другой векторизатор (если нужен отдельно).

Модуль ml_model.py должен обеспечивать:
	•	загрузку артефактов при старте бэкенда;
	•	функцию predict_text(text: str) -> int;
	•	функцию predict_many(texts: List[str]) -> List[int].

5.3. Основные эндпоинты API

Предполагаемый набор маршрутов FastAPI:

1. Проверка состояния сервиса
GET /health

Ответ (пример):

{
  "status": "ok",
  "model_loaded": true
}

2. Предсказание тональности для одного текста
POST /predict_text

Тело запроса:

{
  "text": "Текст отзыва пользователя"
}

Ответ:

{
  "predicted_label": 2,
  "predicted_class_name": "positive"
}

3. Пакетное предсказание для списка текстов
POST /predict_many

Тело запроса:

{
  "texts": [
    "первый отзыв",
    "второй отзыв",
    "третий отзыв"
  ]
}

Ответ:

{
  "predicted_labels": [0, 1, 2]
}

4. Предсказание тональности для CSV-файла
POST /predict_csv

Формат: multipart/form-data, параметр file — CSV с колонкой text.

Ответ (вариант 1 — сразу отдаём CSV-файл):
	•	HTTP-ответ с Content-Type: text/csv, где добавлен столбец predicted_label.

Ответ (вариант 2 — JSON + отдельная ссылка):

{
  "summary": {
    "total_rows": 1000,
    "class_counts": {
      "0": 200,
      "1": 500,
      "2": 300
    }
  },
  "file_url": "/download/predicted_2025_11_29_10_00.csv"
}

5. Оценка модели по CSV с правильными метками
POST /score

Формат: multipart/form-data, параметр file — CSV с колонками text и label.

Логика:
	•	прочитать файл;
	•	сделать предсказания;
	•	посчитать:

from sklearn.metrics import f1_score

macro_f1 = f1_score(true_labels, pred_labels, average="macro")
f1_per_class = f1_score(true_labels, pred_labels, average=None)



Ответ:

{
  "macro_f1": 0.84,
  "f1_per_class": {
    "0": 0.80,
    "1": 0.83,
    "2": 0.89
  },
  "support": {
    "0": 200,
    "1": 500,
    "2": 300
  }
}


⸻

6. Backend: запуск локально

Пример шагов для локального запуска бэкенда:

cd backend

# Создаём виртуальное окружение
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Ставим зависимости
pip install -r requirements.txt

# Запускаем FastAPI через uvicorn
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

После запуска:
	•	Swagger-документация будет доступна по адресу: http://localhost:8000/docs
	•	Здоровье сервиса: http://localhost:8000/health

⸻

7. ML: обучение и сохранение модели

В каталоге ml/ находится код для обучения.

7.1. Скрипт train_model.py

Основные шаги:
	1.	Загрузка обучающего датасета train.csv:
	•	ожидать колонки: text, label, src (источник можно не использовать напрямую в модели).
	2.	Предобработка текстов (те же функции, что на проде).
	3.	Создание пайплайна, например:

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline

pipeline = Pipeline([
    ("vectorizer", TfidfVectorizer(
        ngram_range=(1, 2),
        max_features=50000
    )),
    ("clf", LogisticRegression(max_iter=1000))
])


	4.	Обучение модели на тренировочных данных.
	5.	Оценка на валидационной выборке (можно использовать val.csv или часть train):
	•	расчёт macro-F1 и F1 по классам;
	•	вывод результатов в консоль.
	6.	Сохранение модели и векторизатора (если он не внутри пайплайна):

import joblib
joblib.dump(pipeline, "../backend/model_artifacts/model.joblib")



7.2. Скрипт evaluate_model.py (опционально)
	•	Загружает модель.
	•	Считает метрику на val.csv или test.csv.
	•	Выводит таблицу с F1 по классам и macro-F1.

⸻

8. Frontend: страницы и логика

8.1. Общая идея дизайна
	•	Светлый фон, один-два акцентных цвета.
	•	Минимализм: без лишних декоративных элементов.
	•	Простая навигация: одна страница с вкладками/секциями или несколько страниц.

8.2. Структура интерфейса

Рекомендуется одна главная страница index.html с логическими секциями:
	1.	Раздел “Анализ одного текста”
	•	Textarea для ввода текста.
	•	Кнопка “Определить тональность”.
	•	Блок результатов: цифра 0/1/2 + текст “негативный/нейтральный/позитивный”.
	2.	Раздел “Пакетная классификация CSV”
	•	Форма загрузки файла (<input type="file">).
	•	Кнопка “Загрузить и проанализировать”.
	•	После обработки:
	•	кнопка “Скачать CSV с предсказаниями”;
	•	краткая статистика (кол-во строк, распределение по классам);
	•	по возможности — небольшая таблица с несколькими примерами.
	3.	Раздел “Качество модели (macro-F1)”
	•	Форма загрузки CSV c text и label.
	•	Кнопка “Посчитать качество”.
	•	Блок результатов:
	•	macro-F1;
	•	F1 по каждому классу;
	•	текстовый комментарий (например: “Модель лучше всего различает позитивные отзывы, хуже — негативные”).
	4.	Раздел “Аналитика и фильтры” (минимальная версия)
	•	Круговая диаграмма распределения по классам.
	•	Фильтры:
	•	выпадающий список тональность (все / отрицательные / нейтральные / положительные);
	•	выпадающий список источник.
	•	Таблица отзывов (ограниченное число строк для просмотра).

8.3. Взаимодействие фронта и бэка

JS-модуль api.js:
	•	Функция predictText(text) — делает POST /predict_text.
	•	Функция predictCsv(file) — отправляет POST /predict_csv с FormData.
	•	Функция scoreCsv(file) — отправляет POST /score.

JS-модуль app.js:
	•	Обработка событий формы (submit).
	•	Вызов соответствующих функций из api.js.
	•	Обновление DOM (показ/скрытие блоков, таблиц, графиков).

JS-модуль charts.js:
	•	Инициализация графиков Chart.js.
	•	Обновление данных графиков после получения ответа от бэка.

⸻

9. Деплой и запуск на сервере

9.1. Общая идея

Минимальный рабочий сценарий деплоя:
	1.	Задеплоить backend (FastAPI) на бесплатный хостинг или VPS.
	2.	Задеплоить статический frontend:
	•	либо на тот же хост (Nginx, статика),
	•	либо на отдельный статический хостинг (например, GitHub Pages) и настроить CORS для доступа к API.

9.2. Docker (опционально)

Пример минимального Dockerfile для бэка:

FROM python:3.11-slim

WORKDIR /app

COPY backend/requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY backend /app

EXPOSE 8000

CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]

Пример команд:

docker build -t sentiment-backend -f docker/Dockerfile.backend .
docker run -p 8000:8000 sentiment-backend


⸻

10. Инструкция для проверяющих / пользователей

Эту секцию можно оформить как пошаговое руководство.

10.1. Быстрый старт локально
	1.	Склонировать репозиторий.
	2.	Установить Python 3.10+.
	3.	Перейти в папку backend, создать виртуальное окружение и установить зависимости.
	4.	Убедиться, что в backend/model_artifacts/ лежит model.joblib (если нет — запустить ml/train_model.py).
	5.	Запустить FastAPI через uvicorn.
	6.	Открыть frontend/index.html в браузере или раздавать её через простой HTTP-сервер (например, python -m http.server).
	7.	Проверить работу сценариев:
	•	анализ одного текста;
	•	загрузка CSV для предсказаний;
	•	загрузка CSV с метками для оценки.

10.2. Использование веб-сервиса
	1.	Зайти на URL фронтенда (например: https://<ваш-домен>).
	2.	Перейти в нужный раздел:
	•	“Анализ одного текста” → вставить текст → получить тональность.
	•	“Пакетная классификация CSV” → выбрать файл → дождаться результата → скачать размеченный CSV.
	•	“Качество модели” → выбрать валидационный CSV → получить macro-F1.
	3.	При необходимости использовать фильтры и графики для анализа распределения тональностей.

⸻

11. Возможные улучшения (roadmap)

В дальнейшем можно добавить:
	•	Более сложную модель (RuBERT или другая трансформер-модель).
	•	Балансировку классов, подбор гиперпараметров.
	•	Ручную правку тональностей на сайте и выгрузку обновлённого датасета.
	•	Авторизацию и сохранение истории анализов.
	•	Поддержку других языков.
	•	Отдельный модуль для анализа по районам, категориям услуг, времени.

⸻

12. Контакты и авторство

	•	@Superpuper223
	•	(рабочий сайт).

⸻

13. База данных

В каталоге database/schema.sql лежит схема PostgreSQL (рекомендована версия 13+), которая покрывает хранение отзывов, батчей и метрик.

Таблицы:
	•	sources — справочник источников (code, title).
	•	batches — сведения о загруженных CSV/задачах, статус, class_counts, macro-F1, ссылки на выгрузку.
	•	reviews — строки отзывов с true_label/predicted_label, привязка к батчу и источнику, JSONB с вероятностями.
	•	model_metrics — снимки качества моделей с F1 по классам и параметрами.

Быстрый запуск локально (PostgreSQL):
	1.	createdb sentiment_service
	2.	psql -U <user> -d sentiment_service -f database/schema.sql

Примечания:
	•	используется расширение uuid-ossp для генерации UUID;
	•	jsonb-столбцы class_counts/f1_per_class/support подходят для аналитики и вывода /score;
	•	индексы на predicted_label и src_id упрощают фильтрацию на вкладке аналитики.

⸻

14. Данные и обучение модели

Структура данных:
	•	ml/data/train.csv — обучающая выборка (ID, text, src, label).
	•	ml/data/val.csv — если есть отдельная валидация (опционально).
	•	ml/data/test.csv — тест без меток (ID, text, src).
	•	ml/data/sample_submission.csv — шаблон сабмита (ID, label).

Обучение модели (TF-IDF word+char + LinearSVC/LogReg):
	1.	python -m venv venv && source venv/bin/activate
	2.	pip install -r backend/requirements.txt
	3.	python ml/train_model.py [--model svm|logreg] [--C 1.0] [--word-max-features 100000] [--char-max-features 120000] [--word-min-df 3] [--char-min-df 5]
		•	сохранит модель в backend/model_artifacts/model.joblib
		•	запишет метрики в backend/model_artifacts/metrics.json

Проверка качества на любом CSV с метками:
	•	python ml/evaluate_model.py --data ml/data/train.csv

Формирование сабмита на test.csv:
	•	python ml/make_submission.py --output ml/data/submission.csv

15. Конфигурация бэкенда (ENV)
	•	DATABASE_URL — строка подключения к PostgreSQL (опционально).
	•	MAX_REVIEWS_TO_SAVE — сколько строк сохранять в reviews (0 — не сохранять).
	•	MAX_CSV_BYTES и MAX_CSV_ROWS — лимиты на CSV (0 — без ограничений, можно включить при необходимости).
	•	CORS_ALLOW_ORIGINS — список origin через запятую (или * для всех).
	•	DOWNLOAD_BASE_URL — внешний URL для ссылок на выгрузки; если не задан, ссылки вида /download/<file>.
	•	STORAGE_TTL_HOURS, STORAGE_MAX_FILES — автоочистка storage по времени/количеству (0 — не чистим).
	•	MAX_CONCURRENT_TASKS, TASK_ACQUIRE_TIMEOUT — ограничение числа одновременных задач (семафор, 0 — выкл).
	•	PREDICT_SCORES_MAX_ROWS — считать и сохранять predicted_scores, если строк не больше указанного числа (0 — не считать).
	•	RATE_LIMIT_PER_MIN, RATE_LIMIT_WINDOW_SEC — простой rate-limit на тяжелые эндпоинты (0 — выкл).
	•	`stream=true` в /predict_csv — отдаёт файл chunked StreamingResponse без сохранения.
